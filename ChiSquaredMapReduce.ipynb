{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = './data/reviews_devset.json'\n",
    "PYTHON = 'python3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mr3px in /Users/maxkleinegger/anaconda3/lib/python3.10/site-packages (0.5.1)\n",
      "Requirement already satisfied: mrjob in /Users/maxkleinegger/anaconda3/lib/python3.10/site-packages (0.7.4)\n",
      "Requirement already satisfied: PyYAML>=3.10 in /Users/maxkleinegger/anaconda3/lib/python3.10/site-packages (from mrjob) (6.0)\n"
     ]
    }
   ],
   "source": [
    "! pip3 install mr3px mrjob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting chiSquaredReduce.py\n"
     ]
    }
   ],
   "source": [
    "%%file chiSquaredReduce.py\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "import re\n",
    "import json\n",
    "\n",
    "stopwords = set()\n",
    "\n",
    "class ChiSquaredProcessor(MRJob):\n",
    "\n",
    "    def mapper_1(self, _, line):\n",
    "        \"\"\"\n",
    "        This Mapper return the category and the set of words in the reviewText\n",
    "        Returns a key value pair of: None, (category, word_set)\n",
    "        \"\"\"\n",
    "\n",
    "        data = json.loads(line)\n",
    "        category = data.get('category', '')\n",
    "        reviewText = data.get('reviewText', '')\n",
    "        word_list = re.split('[^a-zA-Z<>^|]+', reviewText.lower())\n",
    "        word_set = set([word for word in word_list if word not in stopwords and word.strip() != '' and len(word) > 1])\n",
    "        yield None, (category, list(word_set))\n",
    "\n",
    "    def reducer_1(self, _, compromised_reviewText):\n",
    "        \"\"\"\n",
    "        This reducer groups the reviews by category and counts the number of all documents\n",
    "        Returns a key value pair of: category, (reviews, N)\n",
    "        \"\"\"\n",
    "\n",
    "        compromised_reviews = list(compromised_reviewText)\n",
    "        N = len(compromised_reviews)\n",
    "        for category, reviews in compromised_reviews:\n",
    "            yield category, (reviews, N)\n",
    "\n",
    "    def mapper_2(self, category, reviews_N):\n",
    "        \"\"\"\n",
    "        This mapper returns all reviews for each category. N (the number of documents), is also passed along per category\n",
    "        Returns a key value pair of: (category, N), reviews\n",
    "        \"\"\"\n",
    "\n",
    "        reviews, N = reviews_N\n",
    "        yield (category, N), reviews\n",
    "\n",
    "       \n",
    "    def reducer_2(self, category_N, reviews):\n",
    "        \"\"\" \n",
    "        This reducer counts the number of documents per category and returns for each category the number of documents and all reviews\n",
    "        Returns a key value pair of: (category, N), (number of documents, reviews)\n",
    "        \"\"\"\n",
    "\n",
    "        all_reviews = list(reviews)\n",
    "        yield category_N, (len(all_reviews), all_reviews)\n",
    "\n",
    "\n",
    "    def mapper_3(self, category_N, all_reviews):\n",
    "        \"\"\" \n",
    "        This mapper groups the terms per category to allow counting their occurences\n",
    "        Returns a key value pair of: (category, term), (1, count, N)\n",
    "        \"\"\"\n",
    "\n",
    "        count, reviews = all_reviews\n",
    "        N = category_N[1]\n",
    "        category = category_N[0]\n",
    "        for review in reviews:\n",
    "            for term in review:\n",
    "                yield (category, term), (1, count, N)\n",
    "\n",
    "    def reducer_3(self, category_term, counts): \n",
    "        \"\"\" \n",
    "        This reducer counts the occurences of each term per category\n",
    "        Returns a key value pair of: (category, term), (number, count, N)\n",
    "        \"\"\"\n",
    "\n",
    "        documents = list(counts)\n",
    "        count = documents[0][1]\n",
    "        N = documents[0][2]\n",
    "        number = sum([n for n, _, _ in documents])\n",
    "        yield category_term, (number, count, N)\n",
    "\n",
    "    def mapper_4(self, category_term, number_count_N):\n",
    "        \"\"\" \n",
    "        This mapper groups the occurences per category for each term\n",
    "        Returns a key value pair of: term, ((category, number), count, N)\n",
    "        \"\"\"\n",
    "\n",
    "        number, count, N = number_count_N\n",
    "        category, term = category_term\n",
    "        yield term, ((category, number), count, N)\n",
    "\n",
    "    def reducer_4(self, term, category_number_count_N):\n",
    "        \"\"\" \n",
    "        This reducer sums the occurences of each term for all categories and adds it to the occurences per category for each term\n",
    "        Returns a key value pair of: term, ([((category, number), count, N)], occurence_overall)\n",
    "        \"\"\"\n",
    "\n",
    "        categories = list(category_number_count_N)\n",
    "        occurence_overall = sum([number for (_, number), _, _ in categories])\n",
    "\n",
    "        yield term, (categories, occurence_overall)\n",
    "\n",
    "    def mapper_5(self, term, categories_occurences):\n",
    "        \"\"\"\n",
    "        This mapper adds the number of all occurences of each term to the occurences per category for each term and groups them by category and term\n",
    "        Returns a key value pair of: (category, term), (number, occurence_overall, count_category, N)\n",
    "        \"\"\"\n",
    "\n",
    "        categories, occurence_overall = categories_occurences\n",
    "        for (category, number), count_category, N in categories:\n",
    "            yield (category, term), (number, occurence_overall, count_category, N)\n",
    "\n",
    "    def reducer_5(self, category_term, number_count_occurence_N):\n",
    "        \"\"\" \n",
    "        This reducer calculates the chi squared value for each term and category.\n",
    "        Returns a key value pair of: (category, term), chi_squared\n",
    "        \"\"\"\n",
    "\n",
    "        number_count_occurence_N = list(number_count_occurence_N)\n",
    "        for number_count_occurence in number_count_occurence_N:\n",
    "            number, occurence, count, N = number_count_occurence\n",
    "            A = number\n",
    "            B = occurence - A\n",
    "            C = count - A\n",
    "            D = N - count - B\n",
    "            chi_squared = N * (A*D - B*C)**2 / ((A+B)*(A+C)*(B+D)*(C+D))\n",
    "            yield category_term, chi_squared\n",
    "\n",
    "    def mapper_6(self, category_term, chi_squared):\n",
    "        \"\"\" \n",
    "        This mapper groups the chi squared values by category.\n",
    "        Returns a key value pair of: category, (term, chi_squared)\n",
    "        \"\"\"\n",
    "\n",
    "        category, term = category_term\n",
    "        yield category, (term, chi_squared)\n",
    "\n",
    "    def reducer_6(self, category, term_chi_squared):\n",
    "        \"\"\" \n",
    "        This reducer sorts the chi squared values and returns the 75 highest values for each category\n",
    "        Returns a key value pair of: category, [term=chi_squared]\n",
    "        \"\"\"\n",
    "        chi_squared_terms = list(term_chi_squared)\n",
    "        chi_squared_terms.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        yield category, ', '.join(f\"{x}={y}\" for x, y in chi_squared_terms[:75])\n",
    "\n",
    "\n",
    "    def steps(self):\n",
    "        return [\n",
    "            MRStep(\n",
    "                mapper   = self.mapper_1,\n",
    "                reducer  = self.reducer_1\n",
    "            ),\n",
    "            MRStep(\n",
    "                mapper   = self.mapper_2,\n",
    "                reducer  = self.reducer_2\n",
    "            ),\n",
    "            MRStep(\n",
    "                mapper   = self.mapper_3,\n",
    "                reducer  = self.reducer_3\n",
    "            ),\n",
    "            MRStep(\n",
    "                mapper   = self.mapper_4,\n",
    "                reducer  = self.reducer_4\n",
    "            ),\n",
    "            MRStep(\n",
    "                mapper   = self.mapper_5,\n",
    "                reducer  = self.reducer_5\n",
    "            ),\n",
    "            MRStep(\n",
    "                mapper   = self.mapper_6,\n",
    "                reducer  = self.reducer_6\n",
    "            )\n",
    "        ]\n",
    "   \n",
    "if __name__ == '__main__':\n",
    "    with open('./data/stopwords.txt', 'r') as f:\n",
    "        stopwords = set(f.read().splitlines())\n",
    "\n",
    "\n",
    "    myjob1 = ChiSquaredProcessor()\n",
    "    with myjob1.make_runner() as runner:\n",
    "        runner.run()\n",
    "        \n",
    "        for key, value in myjob1.parse_output(runner.cat_output()):           \n",
    "            print(key, value, \"\\n\", end='')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running a local MRjob "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs specified for inline runner\n"
     ]
    }
   ],
   "source": [
    "! $PYTHON ./chiSquaredReduce.py $DATA_PATH > ./result/output.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This approach works, some sorting and mergin all lists however is still missing. I didn't add this for the reason I am not fully happy with the overall architecture.\n",
    "My first thought to improving it is by calculating the number of documents for each document and to count all documents into a first Job which we can leverage to a later point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting chiSquaredReduceOptimized.py\n"
     ]
    }
   ],
   "source": [
    "%%file chiSquaredReduceOptimized.py\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "import re\n",
    "import json\n",
    "\n",
    "stopwords = set()\n",
    "category_counts = {}\n",
    "\n",
    "class CountingProcessor(MRJob):\n",
    "    def mapper(self, _, line):\n",
    "        \"\"\" \n",
    "        This mapper returns for each review of a category 1\n",
    "        Returns a key value pair of: category, 1\n",
    "        \"\"\"\n",
    "\n",
    "        data = json.loads(line)\n",
    "        category = data.get('category', '')\n",
    "        yield category, 1\n",
    "\n",
    "    def reducer(self, category, counts):\n",
    "        \"\"\"\n",
    "        This reducer sums the number of reviews per category\n",
    "        Returns a key value pair of: category, number of reviews\n",
    "        \"\"\"\n",
    "        yield category, sum(counts)\n",
    "\n",
    "    def steps(self):\n",
    "        return [\n",
    "            MRStep(\n",
    "                mapper   = self.mapper,\n",
    "                reducer  = self.reducer\n",
    "            )\n",
    "        ]\n",
    "\n",
    "class ChiSquaredProcessor(MRJob):\n",
    "\n",
    "    def mapper_1(self, _, line):\n",
    "        \"\"\" \n",
    "        This mapper returns all terms per category for each document occurence\n",
    "        Returns a key value pair of: (category, word), 1\n",
    "        \"\"\"\n",
    "\n",
    "        data = json.loads(line)\n",
    "        category = data.get('category', '')\n",
    "        reviewText = data.get('reviewText', '')\n",
    "        word_list = re.split('[^a-zA-Z<>^|]+', reviewText.lower())\n",
    "\n",
    "        word_set = set([word for word in word_list if word not in stopwords and word.strip() != '' and len(word) > 1])\n",
    "        for word in word_set:\n",
    "            yield (category, word), 1\n",
    "\n",
    "    def reducer_1(self, category_term, compromised_reviewText):\n",
    "        \"\"\" \n",
    "        This reducer sums the occurences of each term per category\n",
    "        Returns a key value pair of: (category, term), number\n",
    "        \"\"\"\n",
    "\n",
    "        yield category_term, sum(compromised_reviewText)\n",
    "\n",
    "    def mapper_2(self, category_term, count_term):\n",
    "        \"\"\"\n",
    "        This mapper returns all categories which a term is occuring in and the respective number of occurences per category\n",
    "        Returns a key value pair of: term, (category, count_term)\n",
    "        \"\"\"\n",
    "\n",
    "        category, term = category_term\n",
    "        yield term, (category, count_term)\n",
    "\n",
    "    def reducer_2(self, term, category_count):\n",
    "        \"\"\"\n",
    "        This reducer returns the number of occurences of a term in all categories and the number of occurences of all terms\n",
    "        Returns a key value pair of: term, [(category, count_term, number_of_occurences)]\n",
    "        \"\"\"\n",
    "\n",
    "        all_categories_count = list(category_count)\n",
    "        number_of_occurences = sum([count for _, count in all_categories_count])\n",
    "        yield term, [(category, count_term, number_of_occurences) for category, count_term in all_categories_count]\n",
    "\n",
    "    def mapper_3(self, term, list_category_count):\n",
    "        \"\"\"\n",
    "        This mapper groups the occurences of each term per category\n",
    "        Returns a key value pair of: (category, term), (count_term, number_of_occurences)\n",
    "        \"\"\"\n",
    "\n",
    "        for category_count in list_category_count:\n",
    "            category, count_term, number_of_occurences = category_count\n",
    "            yield (category, term), (count_term, number_of_occurences)\n",
    "\n",
    "    def reducer_3(self, category_term, list_category_count): \n",
    "        \"\"\"\n",
    "        This reducer calculates the chi squared value for each term per category.\n",
    "        Returns a key value pair of: (category, term), chi_squared\n",
    "        \"\"\"\n",
    "\n",
    "        number_count_occurence_N = list(list_category_count)\n",
    "        category, _ = category_term\n",
    "        for count in number_count_occurence_N:\n",
    "            count_term, number_of_occurences = count\n",
    "            A = count_term\n",
    "            B = number_of_occurences - count_term\n",
    "            C = category_counts[category] - count_term\n",
    "            D = category_counts[\"N\"] - category_counts[category] - B\n",
    "            chi_squared = category_counts[\"N\"] * (A*D - B*C)**2 / ((A+B)*(A+C)*(B+D)*(C+D))\n",
    "            yield category_term, chi_squared\n",
    "\n",
    "    def mapper_4(self, category_term, chi_squared):\n",
    "        \"\"\"\n",
    "        This mapper groups the chi squared values for each term by category. Additionally it returns all terms per category.\n",
    "        Returns a key value pair of: category, (term, chi_squared)\n",
    "        \"\"\"\n",
    "\n",
    "        category, term = category_term\n",
    "        yield category, (term, chi_squared)\n",
    "        yield None, term\n",
    "\n",
    "    def reducer_4(self, category, term_chi_squared):\n",
    "        \"\"\"\n",
    "        This reducer sorts the chi squared values and returns the 75 highest values for each category. If no category is given, all terms are returned.\n",
    "        Returns a key value pair of: category, [term=chi_squared]\n",
    "        \"\"\"\n",
    "\n",
    "        if category is None:\n",
    "            all_words = set(term_chi_squared)\n",
    "            all_words = sorted(all_words)\n",
    "            yield ', '.join(all_words), \"\"\n",
    "        else:\n",
    "            chi_squared_terms = list(term_chi_squared)\n",
    "            chi_squared_terms.sort(key=lambda x: x[1], reverse=True)\n",
    "            yield category, ', '.join(f\"{x}={y}\" for x, y in chi_squared_terms[:75])\n",
    "\n",
    "\n",
    "    def steps(self):\n",
    "        return [\n",
    "            MRStep(\n",
    "                mapper   = self.mapper_1,\n",
    "                reducer  = self.reducer_1\n",
    "            ),\n",
    "            MRStep(\n",
    "                mapper   = self.mapper_2,\n",
    "                reducer  = self.reducer_2\n",
    "            ),\n",
    "            MRStep(\n",
    "                mapper   = self.mapper_3,\n",
    "                reducer  = self.reducer_3\n",
    "            ),\n",
    "            MRStep(\n",
    "                mapper   = self.mapper_4,\n",
    "                reducer  = self.reducer_4\n",
    "            )\n",
    "        ]\n",
    "   \n",
    "if __name__ == '__main__':\n",
    "    myjob = CountingProcessor()\n",
    "    with myjob.make_runner() as runner:\n",
    "        runner.run()\n",
    "        for key, value in myjob.parse_output(runner.cat_output()):           \n",
    "            category_counts[key] = value\n",
    "        category_counts[\"N\"] = sum(category_counts.values())\n",
    "\n",
    "    with open('./data/stopwords.txt', 'r') as f:\n",
    "        stopwords = set(f.read().splitlines())\n",
    "\n",
    "    mrjob = ChiSquaredProcessor()\n",
    "    with mrjob.make_runner() as runner:\n",
    "        runner.run()\n",
    "        \n",
    "        for key, value in mrjob.parse_output(runner.cat_output()):           \n",
    "            print(key, value, \"\\n\", end='')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs specified for inline runner\n",
      "No configs specified for inline runner\n"
     ]
    }
   ],
   "source": [
    "! $PYTHON ./chiSquaredReduceOptimized.py $DATA_PATH > ./result/output.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
