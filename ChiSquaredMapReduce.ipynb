{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = 'reviews_devset.json'\n",
    "PYTHON = 'python3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mr3px in /Users/maxkleinegger/anaconda3/lib/python3.10/site-packages (0.5.1)\n",
      "Requirement already satisfied: mrjob in /Users/maxkleinegger/anaconda3/lib/python3.10/site-packages (0.7.4)\n",
      "Requirement already satisfied: PyYAML>=3.10 in /Users/maxkleinegger/anaconda3/lib/python3.10/site-packages (from mrjob) (6.0)\n"
     ]
    }
   ],
   "source": [
    "! pip3 install mr3px mrjob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing chiSquaredReduce.py\n"
     ]
    }
   ],
   "source": [
    "%%file chiSquaredReduce.py\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "# from mr3px.csvprotocol import CsvProtocol\n",
    "import re\n",
    "\n",
    "WORD_RE = re.split('[^a-zA-Z<>^|]+', line)\n",
    "\n",
    "class ChiSquaredProcessor(MRJob):\n",
    "\n",
    "    \n",
    "    def mapper_count_title(self, _, line):\n",
    "        result = next(csv.reader([line])) # extract columns from line\n",
    "\n",
    "        title = result[6]\n",
    "        author = result[7]\n",
    "        nCheckouts = result[5]\n",
    "\n",
    "        #skip sparse entries and header\n",
    "        if title == \"Title\" or author == \"\" or title == \"\" or nCheckouts == \"0\": \n",
    "            return  \n",
    "\n",
    "        yield (author,title), nCheckouts\n",
    "\n",
    "\n",
    "    def mapper_count_title(self, _, line):\n",
    "        # Tokenizes each line by using whitespaces, tabs, digits, and the specified characters as delimiters\n",
    "        word_list = re.split('[^a-zA-Z<>^|]+', line)\n",
    "        \n",
    "        # For loop through the terms in pre-processed list\n",
    "        for word in word_list:\n",
    "            yield (word.lower(), 1)\n",
    "\n",
    "    # The reducer now simply counts how often a title is checked out\n",
    "    def reducer_title_reducer(self,authorTitle,checkouts):        \n",
    "        count = 0\n",
    "        author, title = authorTitle\n",
    "\n",
    "        for rec in checkouts:\n",
    "            count = count + int(rec)\n",
    "\n",
    "        # CsvProtocol needs None key for output\n",
    "        yield None, (author,title,count) \n",
    "\n",
    "    # The mapper of the second round sets as key the author\n",
    "    def mapper_top_title(self, _, line):\n",
    "        result = line # input from last round already a list of strings\n",
    "\n",
    "        author = result[0]\n",
    "        title = result[1]\n",
    "        nCheckouts = result[2]\n",
    "\n",
    "        yield author, (title,nCheckouts)\n",
    "\n",
    "    # The combiner functions same as reducer, except that it emits a pair. \n",
    "    # This is necessary so the output of the combiner matches the mapper\n",
    "    def combiner_top_title(self,author,titleCheckouts):\n",
    "        mostCheckedOutTitle = \"\"\n",
    "        mostCheckouts = 0\n",
    "\n",
    "        for (title,nCheckouts) in titleCheckouts:\n",
    "            if int(nCheckouts) > mostCheckouts:\n",
    "                mostCheckouts = int(nCheckouts)\n",
    "                mostCheckedOutTitle = title\n",
    "\n",
    "        if mostCheckouts > 0: \n",
    "            yield author, (mostCheckedOutTitle,mostCheckouts)\n",
    "\n",
    "     # The reducer now visits all titles for the author key and only emits \n",
    "     # a tuple with the title that was checked out the most for each author\n",
    "    def reducer_top_title(self,author,titleCheckouts):\n",
    "        mostCheckedOutTitle = \"\"\n",
    "        mostCheckouts = 0\n",
    "\n",
    "        for (title,nCheckouts) in titleCheckouts:\n",
    "            if int(nCheckouts) > mostCheckouts:\n",
    "                mostCheckouts = int(nCheckouts)\n",
    "                mostCheckedOutTitle = title\n",
    "\n",
    "        if mostCheckouts > 0: \n",
    "            #CsvProtocol needs None key for output\n",
    "            yield None, (author, mostCheckedOutTitle) \n",
    "\n",
    "    def steps(self):\n",
    "        return [\n",
    "            MRStep(mapper   = self.mapper_count_title,\n",
    "                   reducer  = self.reducer_title_reducer),\n",
    "            MRStep(mapper   = self.mapper_top_title,\n",
    "                   combiner = self.combiner_top_title,\n",
    "                   reducer  = self.reducer_top_title)\n",
    "        ]\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    myjob1 = ChiSquaredProcessor()\n",
    "    with myjob1.make_runner() as runner:\n",
    "        runner.run()\n",
    "        \n",
    "        for key, value in myjob1.parse_output(runner.cat_output()):           \n",
    "            print(key, value, \"\\n\", end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting chiSquaredReduce.py\n"
     ]
    }
   ],
   "source": [
    "%%file chiSquaredReduce.py\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "# from mr3px.csvprotocol import CsvProtocol\n",
    "import re\n",
    "import json\n",
    "\n",
    "stopwords = set()\n",
    "\n",
    "class ChiSquaredProcessor(MRJob):\n",
    "    def mapper_category_contains_term(self, _, line):\n",
    "        # Mapper for counting the number of documents in which a term appears in a category\n",
    "        data = json.loads(line)\n",
    "        category = data.get('category', '')\n",
    "        reviewText = data.get('reviewText', '')\n",
    "        \n",
    "        word_list = re.split('[^a-zA-Z<>^|]+', reviewText.lower())\n",
    "        word_set = set([word for word in word_list if word not in stopwords and word.strip() != '' and len(word) > 1])\n",
    "        yield category, list(word_set)\n",
    "\n",
    "\n",
    "    def reducer_count_categories_contains_term(self, category, compromised_reviewText):\n",
    "        # Reducer for counting the number of documents in which a term appears in a category\n",
    "        compromised_reviews = list(compromised_reviewText)\n",
    "        yield category, (len(compromised_reviews), compromised_reviews)\n",
    "\n",
    "    def mapper_term_for_categories(self, category, count_reviews):\n",
    "        # Mapper for counting the all different combinations of terms occuring in a all categories\n",
    "        count, reviews = count_reviews\n",
    "        for review in reviews:\n",
    "            for term in review:\n",
    "                yield (category, term), (1, count)\n",
    "\n",
    "    def reducer_term_for_categories(self, category, counts):\n",
    "        # Reducer for collecting each category of t\n",
    "        documents = list(counts)\n",
    "        count = documents[0][1]\n",
    "        number = sum([n for n, _ in documents])\n",
    "        yield category, (number, count)\n",
    "\n",
    "    def mapper_3(self, term, category_counts):\n",
    "        # Mapper for counting the all different combinations of terms occuring in a all categories\n",
    "        for cat, cnt in category_counts:\n",
    "            yield cat, (term, count)\n",
    "\n",
    "        #yield term, category_counts\n",
    "\n",
    "    def reducer_3(self, term, category_counts):\n",
    "        token_counts = list(category_counts)\n",
    "        #A =\n",
    "        #C =\n",
    "\n",
    "\n",
    "        yield term, token_counts\n",
    "\n",
    "    def steps(self):\n",
    "        return [\n",
    "            MRStep(\n",
    "                mapper   = self.mapper_category_contains_term,\n",
    "                reducer  = self.reducer_count_categories_contains_term\n",
    "            ),\n",
    "            MRStep(\n",
    "                mapper   = self.mapper_term_for_categories,\n",
    "                reducer  = self.reducer_term_for_categories\n",
    "            )\n",
    "            #MRStep(\n",
    "            #    mapper   = self.mapper3,\n",
    "            #    reducer  = self.reducer3\n",
    "            #)\n",
    "        ]\n",
    "   \n",
    "if __name__ == '__main__':\n",
    "    with open('./stopwords.txt', 'r') as f:\n",
    "        stopwords = set(f.read().splitlines())\n",
    "\n",
    "\n",
    "    myjob1 = ChiSquaredProcessor()\n",
    "    with myjob1.make_runner() as runner:\n",
    "        runner.run()\n",
    "        \n",
    "        for key, value in myjob1.parse_output(runner.cat_output()):           \n",
    "            print(key, value, \"\\n\", end='')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running a local MRjob "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs specified for inline runner\n"
     ]
    }
   ],
   "source": [
    "! $PYTHON ./chiSquaredReduce.py $DATA_PATH > output.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! $PYTHON ./chiSquaredReduce.py --hadoop-streaming-jar /opt/homebrew/opt/hadoop/libexec/share/hadoop/tools/lib/hadoop-streaming-3.4.0.jar \\\n",
    "-r hadoop hdfs:///user/maxkleinegger/reviews/reviews_devset.json --file ./chiSquaredReduce.py > output.txt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
